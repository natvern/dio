\newglossaryentry{episode}
{
    name=episode,
    description={Collection of steps before the goal is achieved OR the agent 
            terminates (i.e. crash into obstacles)}
}

\newglossaryentry{frame}
{
    name=frame,
    description={Step taken by the agent that advances the environment}
}

\newglossaryentry{meta-learning}
{
    name=meta-learning,
    description={How well an agent trained in one environment 
        adapts to a new environment}
}

\newglossaryentry{reinforcement learning}
{
    name=reinforcement learning (RL),
    description={Trial-and-error AI algorithm based on Markov Decision Process 
            and the Bayesian rule}
}

\newglossaryentry{learning rate}
{
    name=learning rate,
    description={Hyperparameter defining how slowly or quickly the agent 
            learns from experience}
}

\newglossaryentry{discount factor}
{
    name=discount factor,
    description={Hyperparameter definining how much future rewards 
    affect the current decision (i.e. a high discount factor means we care less 
    about the future)}
}

\newglossaryentry{state}
{
    name=state,
    description={Internal representation of the environment specific to Reinforcement Learning}
}

\newglossaryentry{Observation}
{
    name=observation,
    description={The input gathered by external or/and internal sensors}
}

\newglossaryentry{reward}
{
    name=reward,
    description={Numerical value often normalized given to the agent after execution of an action}
}

\newglossaryentry{Reward shaping}
{
    name=reward shaping,
    description={Concept behind adapting the reward function to minimize human bias}
}

\newglossaryentry{return}
{
    name=return,
    description={Summation of rewards for a given episode}
}

\newglossaryentry{exploration}
{
    name=exploration vs. exploitation,
    description={Dilemma in Reinforcement Learning that defines whether to choose 
    an unexplored or explored state at a given timestep}
}


\newglossaryentry{norms}
{
    name=norm,
    description={Textual guides translated into the reward function}
}

\newglossaryentry{policy}
{
    name=policy,
    description={Resulting function of training that maps a state to an action}
}


